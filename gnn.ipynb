{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: GNN (Generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# dataset contains 23991306 rows x 4 columns\n",
    "num_nodes = 10000 # Truncated because of limited resource\n",
    "dataset = pd.read_csv('/mnt/f/Personal/prj-ml-train-collision-avoidance/dataset/dataset.csv').head(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "dataset['train_speed'] = (dataset['train_speed'] - dataset['train_speed'].mean()) / dataset['train_speed'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for index, row in dataset.iterrows():\n",
    "    obs_y = row['obs_y']\n",
    "    obs_x = row['obs_x']\n",
    "    train_speed = row['train_speed']\n",
    "    action = row['action']\n",
    "    \n",
    "    # Add node with features\n",
    "    G.add_node(index, obs_y=obs_y, obs_x=obs_x, train_speed=train_speed, action=action)\n",
    "    \n",
    "    # Add edges (example: connect consecutive rows)\n",
    "    if index > 0:\n",
    "        G.add_edge(index - 1, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GNN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edges = [(i, i+1) for i in range(num_nodes-1)]  # Example edges\n",
    "\n",
    "x = torch.randn((num_nodes, 4))  # 4 features per node\n",
    "\n",
    "# Edge index\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data.y = torch.randint(0, 2, (num_nodes,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Training:Test Split: 80:20\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_data \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m num_nodes)]\n\u001b[1;32m      6\u001b[0m test_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m num_nodes):]\n\u001b[1;32m      7\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader([train_data], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/software/miniconda3/envs/prj_train/lib/python3.11/site-packages/torch_geometric/data/data.py:577\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store[key]\n",
      "File \u001b[0;32m~/software/miniconda3/envs/prj_train/lib/python3.11/site-packages/torch_geometric/data/storage.py:118\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[key]\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# TASK: Train the model\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Training:Test Split: 80:20\n",
    "train_data = data[:int(0.8 * num_nodes)]\n",
    "test_data = data[int(0.8 * num_nodes):]\n",
    "train_loader = DataLoader([train_data], batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader([test_data], batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize Model\n",
    "model = GCN(in_channels=4, hidden_channels=16, out_channels=2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train Model\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "for batch in test_loader:\n",
    "    out = model(batch)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct += (pred == batch.y).sum().item()\n",
    "accuracy = correct / len(test_data.y)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prj_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
